# LLM Scaler

LLM Scaler is an GenAI solution for text generation, image generation, video generation etc running on [Intel® Arc™ Pro B60 GPUs](https://www.intel.com/content/www/us/en/products/docs/discrete-gpus/arc/workstations/b-series/overview.html). LLM Scalar leverages standard frameworks such as vLLM, ComfyUI, Xinference etc and ensures the best performance for State-of-Art GenAI models running on Arc B60 GPUs.

---

## LLM Scaler vLLM

llm-scaler-vllm supports running text generation models using vLLM:  

- [Getting Started](vllm/README.md/#1-getting-started-and-usage)
- [Features](vllm/README.md/#2-advanced-features)
- [Supported Models](vllm/README.md/#3-supported-models)

## LLM Scaler Omni (experimental)

llm-scaler-omni supports running image/voice/video generation etc using ComfyUI, Xinference:

- [Getting Started](omni/README.md/#getting-started-with-omni-docker-image)
- [ComfyUI Support](omni/README.md/#comfyui)
- [Xinference Support](omni/README.md/#xinference)

---
## Get Support
- Please report a bug or raise a feature request by opening a [Github Issue](https://github.com/intel/llm-scaler/issues)